{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport data_creater\n",
    "%autoreload 1\n",
    "\n",
    "from data_creater import *\n",
    "import re, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Agilent Technologies Inc.</td>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines Group Inc.</td>\n",
       "      <td>AAL</td>\n",
       "      <td>American Airlines Group Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Advance Auto Parts Inc.</td>\n",
       "      <td>AAP</td>\n",
       "      <td>Advance Auto Parts Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>Xylem Inc.</td>\n",
       "      <td>XYL</td>\n",
       "      <td>Xylem Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>Yum! Brands Inc.</td>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473</td>\n",
       "      <td>Zimmer Biomet Holdings Inc.</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet Holdings Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>Zions Bancorporation N.A.</td>\n",
       "      <td>ZION</td>\n",
       "      <td>Zions Bancorporation N.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>Zoetis Inc. Class A</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis Inc. Class A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company Symbol                      Industry\n",
       "0       Agilent Technologies Inc.      A     Agilent Technologies Inc.\n",
       "1    American Airlines Group Inc.    AAL  American Airlines Group Inc.\n",
       "2         Advance Auto Parts Inc.    AAP       Advance Auto Parts Inc.\n",
       "3                      Apple Inc.   AAPL                    Apple Inc.\n",
       "4                     AbbVie Inc.   ABBV                   AbbVie Inc.\n",
       "..                            ...    ...                           ...\n",
       "471                    Xylem Inc.    XYL                    Xylem Inc.\n",
       "472              Yum! Brands Inc.    YUM              Yum! Brands Inc.\n",
       "473   Zimmer Biomet Holdings Inc.    ZBH   Zimmer Biomet Holdings Inc.\n",
       "474     Zions Bancorporation N.A.   ZION     Zions Bancorporation N.A.\n",
       "475           Zoetis Inc. Class A    ZTS           Zoetis Inc. Class A\n",
       "\n",
       "[476 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = companies()\n",
    "symbols = stocks['Symbol'].values.tolist()\n",
    "stocks\n",
    "# stocks[stocks.Industry == 'Technology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "start_date = '20180701' \n",
    "end_date = '20191127'\n",
    "rerun = []\n",
    "#download quotes from yahoo and save to directory\n",
    "for ticker in symbols:\n",
    "    try:\n",
    "        download = Downloader(ticker,start_date, end_date)\n",
    "        download.save()\n",
    "    except:\n",
    "        rerun.append(ticker)\n",
    "print(len(rerun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "start_date = '20180701' \n",
    "end_date = '20191127'\n",
    "rerun_last = rerun\n",
    "print(len(rerun_last))\n",
    "rerun = []\n",
    "#download quotes from yahoo and save to directory\n",
    "for ticker in rerun_last:\n",
    "    try:\n",
    "        download = Downloader(ticker,start_date, end_date)\n",
    "        download.save()\n",
    "    except:\n",
    "        rerun.append(ticker)\n",
    "print(len(rerun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELG\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./data/{}/quotes.csv\"\n",
    "rerun = []\n",
    "for ticker in symbols:\n",
    "    try:\n",
    "        if os.path.isfile(file_path.format(ticker)):\n",
    "            feature = Feature_Selection.read_csv(ticker, file_path.format(ticker))\n",
    "            feature.calculate_features()\n",
    "            feature.normalize_data()\n",
    "            feature.save_stock_data()\n",
    "            feature.save_normalized_data()\n",
    "    except:\n",
    "        print(ticker)\n",
    "        rerun.append(ticker)\n",
    "        \n",
    "#         target_dfs = pd.read_csv('./data/{0}/normalized.csv'.format(ticker),  index_col=[0], parse_dates=[0])\n",
    "#         finaldf = target_dfs\n",
    "#         finaldf.to_csv('./data/{0}/all_normalized.csv'.format(ticker), index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/{}/quotes.csv\"\n",
    "rerun_list = rerun\n",
    "rerun = []\n",
    "for ticker in rerun_list:\n",
    "    try:\n",
    "        if os.path.isfile(file_path.format(ticker)):\n",
    "            feature = Feature_Selection.read_csv(ticker, file_path.format(ticker))\n",
    "            feature.calculate_features()\n",
    "            feature.normalize_data()\n",
    "            feature.save_stock_data()\n",
    "            feature.save_normalized_data()\n",
    "    except:\n",
    "        print(ticker)\n",
    "        rerun.append(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bacon_huang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "symbol = 'MSFT'\n",
    "target_dfs = pd.read_csv('./data/{0}/normalized.csv'.format(symbol),  index_col=[0], parse_dates=[0])\n",
    "dfs = []\n",
    "for symbol_tem in symbols:\n",
    "#     try:\n",
    "        if symbol_tem == symbol or symbol_tem == 'BTC-USD':\n",
    "            pass\n",
    "        df = pd.read_csv('./data/{0}/normalized.csv'.format(symbol_tem), index_col=[0], parse_dates=[0]) \n",
    "        df = df.set_index(df['date'])\n",
    "        specific_col = [col for col in df.columns if re.match('normal.*', col)]\n",
    "        specific_col = [col for col in specific_col if col != 'normal_weekday']\n",
    "        df_part = df[specific_col]\n",
    "        df_part.columns = [symbol_tem + '_' + col for col in df_part.columns]   # if not bool(re.match('.*delta.*', col)) \n",
    "        dfs.append(df_part)\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "finaldf_ = pd.concat(dfs, axis=1, join='outer')\n",
    "finaldf_['date'] = finaldf_.index\n",
    "# finaldf_ = finaldf_.reset_index(['date'])\n",
    "finaldf = target_dfs.merge(finaldf_, on='date', how='left')\n",
    "finaldf.to_csv('./data/{0}/all_normalized.csv'.format(symbol), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bacon_huang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAL\n",
      "AAP\n",
      "AAPL\n",
      "ABBV\n",
      "ABC\n",
      "ABMD\n",
      "ABT\n",
      "ACN\n",
      "ADBE\n",
      "ADI\n",
      "ADM\n",
      "ADP\n",
      "ADS\n",
      "ADSK\n",
      "AEE\n",
      "AEP\n",
      "AES\n",
      "AFL\n",
      "AGN\n",
      "AIG\n",
      "AIV\n",
      "AJG\n",
      "AKAM\n",
      "ALB\n",
      "ALGN\n",
      "ALK\n",
      "ALL\n",
      "ALLE\n",
      "ALXN\n",
      "AMAT\n",
      "AMCR\n",
      "AMD\n",
      "AME\n",
      "AMG\n",
      "AMGN\n",
      "AMP\n",
      "AMT\n",
      "AMZN\n",
      "ANET\n",
      "ANSS\n",
      "ANTM\n",
      "AON\n",
      "APA\n",
      "APD\n",
      "APH\n",
      "APTV\n",
      "ARE\n",
      "ARNC\n",
      "ATO\n",
      "ATVI\n",
      "AVB\n",
      "AVGO\n",
      "AVY\n",
      "AWK\n",
      "AXP\n",
      "AZO\n",
      "BA\n",
      "BAC\n",
      "BAX\n",
      "BBT\n",
      "BBY\n",
      "BDX\n",
      "BEN\n",
      "BIIB\n",
      "BK\n",
      "BKNG\n",
      "BLK\n",
      "BLL\n",
      "BMY\n",
      "BR\n",
      "BSX\n",
      "BWA\n",
      "BXP\n",
      "C\n",
      "CAG\n",
      "CAH\n",
      "CAT\n",
      "CB\n",
      "CBOE\n",
      "CBRE\n",
      "CBS\n",
      "CCI\n",
      "CCL\n",
      "CDNS\n",
      "CDW\n",
      "CE\n",
      "CELG\n",
      "CERN\n",
      "CF\n",
      "CFG\n",
      "CHD\n",
      "CHRW\n",
      "CHTR\n",
      "CI\n",
      "CINF\n",
      "CL\n",
      "CLX\n",
      "CMA\n",
      "CMCSA\n",
      "CME\n",
      "CMG\n",
      "CMI\n",
      "CMS\n",
      "CNC\n",
      "CNP\n",
      "COF\n",
      "COG\n",
      "COO\n",
      "COP\n",
      "COST\n",
      "COTY\n",
      "CPB\n",
      "CPRI\n",
      "CPRT\n",
      "CRM\n",
      "CSCO\n",
      "CSX\n",
      "CTAS\n",
      "CTL\n",
      "CTSH\n",
      "CTXS\n",
      "CVS\n",
      "CVX\n",
      "CXO\n",
      "D\n",
      "DAL\n",
      "DD\n",
      "DE\n",
      "DFS\n",
      "DG\n",
      "DGX\n",
      "DHI\n",
      "DHR\n",
      "DIS\n",
      "DISCA\n",
      "DISCK\n",
      "DISH\n",
      "DLR\n",
      "DLTR\n",
      "DOV\n",
      "DRE\n",
      "DRI\n",
      "DTE\n",
      "DUK\n",
      "DVA\n",
      "DVN\n",
      "DXC\n",
      "EA\n",
      "EBAY\n",
      "ECL\n",
      "ED\n",
      "EFX\n",
      "EIX\n",
      "EL\n",
      "EMR\n",
      "EOG\n",
      "EQIX\n",
      "EQR\n",
      "ES\n",
      "ESS\n",
      "ETFC\n",
      "ETN\n",
      "ETR\n",
      "EVRG\n",
      "EW\n",
      "EXC\n",
      "EXPD\n",
      "EXPE\n",
      "EXR\n",
      "F\n",
      "FANG\n",
      "FAST\n",
      "FB\n",
      "FBHS\n",
      "FCX\n",
      "FDX\n",
      "FE\n",
      "FFIV\n",
      "FIS\n",
      "FISV\n",
      "FITB\n",
      "FLIR\n",
      "FLT\n",
      "FMC\n",
      "FRC\n",
      "FRT\n",
      "FTNT\n",
      "FTV\n",
      "GD\n",
      "GE\n",
      "GILD\n",
      "GIS\n",
      "GL\n",
      "GLW\n",
      "GM\n",
      "GOOG\n",
      "GOOGL\n",
      "GPC\n",
      "GPN\n",
      "GPS\n",
      "GRMN\n",
      "GS\n",
      "GWW\n",
      "HAL\n",
      "HAS\n",
      "HBAN\n",
      "HBI\n",
      "HCA\n",
      "HD\n",
      "HES\n",
      "HIG\n",
      "HLT\n",
      "HOG\n",
      "HOLX\n",
      "HON\n",
      "HP\n",
      "HPE\n",
      "HPQ\n",
      "HRB\n",
      "HRL\n",
      "HSIC\n",
      "HST\n",
      "HSY\n",
      "HUM\n",
      "IBM\n",
      "ICE\n",
      "IDXX\n",
      "IEX\n",
      "IFF\n",
      "ILMN\n",
      "INCY\n",
      "INFO\n",
      "INTC\n",
      "INTU\n",
      "IP\n",
      "IPG\n",
      "IQV\n",
      "IR\n",
      "IRM\n",
      "ISRG\n",
      "IT\n",
      "ITW\n",
      "IVZ\n",
      "JCI\n",
      "JEC\n",
      "JNJ\n",
      "JNPR\n",
      "JPM\n",
      "JWN\n",
      "K\n",
      "KEY\n",
      "KEYS\n",
      "KHC\n",
      "KIM\n",
      "KLAC\n",
      "KMB\n",
      "KMI\n",
      "KMX\n",
      "KO\n",
      "KR\n",
      "KSS\n",
      "KSU\n",
      "L\n",
      "LB\n",
      "LDOS\n",
      "LEG\n",
      "LEN\n",
      "LH\n",
      "LHX\n",
      "LIN\n",
      "LKQ\n",
      "LLY\n",
      "LMT\n",
      "LNC\n",
      "LNT\n",
      "LOW\n",
      "LRCX\n",
      "LUV\n",
      "LVS\n",
      "LW\n",
      "LYB\n",
      "M\n",
      "MA\n",
      "MAA\n",
      "MAC\n",
      "MAR\n",
      "MAS\n",
      "MCD\n",
      "MCHP\n",
      "MCK\n",
      "MCO\n",
      "MDLZ\n",
      "MDT\n",
      "MET\n",
      "MGM\n",
      "MKC\n",
      "MKTX\n",
      "MLM\n",
      "MMC\n",
      "MMM\n",
      "MNST\n",
      "MO\n",
      "MOS\n",
      "MPC\n",
      "MRK\n",
      "MRO\n",
      "MS\n",
      "MSCI\n",
      "MSFT\n",
      "MSI\n",
      "MTB\n",
      "MTD\n",
      "MU\n",
      "MXIM\n",
      "NBL\n",
      "NCLH\n",
      "NDAQ\n",
      "NEE\n",
      "NEM\n",
      "NFLX\n",
      "NI\n",
      "NKE\n",
      "NLSN\n",
      "NOC\n",
      "NOV\n",
      "NRG\n",
      "NSC\n",
      "NTAP\n",
      "NTRS\n",
      "NUE\n",
      "NVDA\n",
      "NWL\n",
      "NWS\n",
      "O\n",
      "OKE\n",
      "OMC\n",
      "ORCL\n",
      "ORLY\n",
      "OXY\n",
      "PAYX\n",
      "PBCT\n",
      "PCAR\n",
      "PEG\n",
      "PEP\n",
      "PFE\n",
      "PFG\n",
      "PG\n",
      "PGR\n",
      "PH\n",
      "PKG\n",
      "PKI\n",
      "PLD\n",
      "PM\n",
      "PNC\n",
      "PNR\n",
      "PNW\n",
      "PPG\n",
      "PPL\n",
      "PRU\n",
      "PSA\n",
      "PSX\n",
      "PVH\n",
      "PWR\n",
      "PXD\n",
      "PYPL\n",
      "QCOM\n",
      "QRVO\n",
      "RCL\n",
      "RE\n",
      "REGN\n",
      "RF\n",
      "RHI\n",
      "RJF\n",
      "RL\n",
      "RMD\n",
      "ROK\n",
      "ROL\n",
      "ROP\n",
      "ROST\n",
      "RSG\n",
      "RTN\n",
      "SBAC\n",
      "SBUX\n",
      "SCHW\n",
      "SEE\n",
      "SHW\n",
      "SIVB\n",
      "SJM\n",
      "SLB\n",
      "SLG\n",
      "SNA\n",
      "SNPS\n",
      "SO\n",
      "SPG\n",
      "SPGI\n",
      "SRE\n",
      "STI\n",
      "STT\n",
      "STX\n",
      "STZ\n",
      "SWK\n",
      "SWKS\n",
      "SYF\n",
      "SYK\n",
      "SYY\n",
      "T\n",
      "TDG\n",
      "TEL\n",
      "TFX\n",
      "TGT\n",
      "TIF\n",
      "TJX\n",
      "TMO\n",
      "TMUS\n",
      "TPR\n",
      "TRIP\n",
      "TROW\n",
      "TRV\n",
      "TSCO\n",
      "TSN\n",
      "TTWO\n",
      "TWTR\n",
      "TXN\n",
      "TXT\n",
      "UA\n",
      "UAA\n",
      "UAL\n",
      "UDR\n",
      "UHS\n",
      "ULTA\n",
      "UNH\n",
      "UNM\n",
      "UNP\n",
      "UPS\n",
      "URI\n",
      "USB\n",
      "UTX\n",
      "V\n",
      "VFC\n",
      "VIAB\n",
      "VLO\n",
      "VMC\n",
      "VNO\n",
      "VRSK\n",
      "VRSN\n",
      "VRTX\n",
      "VTR\n",
      "VZ\n",
      "WAB\n",
      "WAT\n",
      "WBA\n",
      "WCG\n",
      "WDC\n",
      "WEC\n",
      "WELL\n",
      "WFC\n",
      "WHR\n",
      "WLTW\n",
      "WM\n",
      "WMB\n",
      "WMT\n",
      "WRK\n",
      "WU\n",
      "WY\n",
      "WYNN\n",
      "XEC\n",
      "XEL\n",
      "XLNX\n",
      "XOM\n",
      "XRAY\n",
      "XYL\n",
      "YUM\n",
      "ZBH\n",
      "ZION\n",
      "ZTS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for symbol in symbols:\n",
    "    print(symbol)\n",
    "    target_dfs = pd.read_csv('./data/{0}/normalized.csv'.format(symbol),  index_col=[0], parse_dates=[0])\n",
    "    dfs = []\n",
    "    for symbol_tem in symbols:\n",
    "        if symbol_tem == symbol or symbol_tem == 'BTC-USD':\n",
    "            pass\n",
    "        df = pd.read_csv('./data/{0}/normalized.csv'.format(symbol_tem), index_col=[0], parse_dates=[0]) \n",
    "        df = df.set_index(df['date'])\n",
    "        specific_col = [col for col in df.columns if re.match('normal.*', col)]\n",
    "        specific_col = [col for col in specific_col if col != 'normal_weekday']\n",
    "        df_part = df[specific_col]\n",
    "        df_part.columns = [symbol_tem + '_' + col for col in df_part.columns]   # if not bool(re.match('.*delta.*', col)) \n",
    "        dfs.append(df_part)\n",
    "\n",
    "    finaldf_ = pd.concat(dfs, axis=1, join='outer')\n",
    "    finaldf_['date'] = finaldf_.index\n",
    "#     finaldf_ = finaldf_.reset_index(['date'])\n",
    "    finaldf = target_dfs.merge(finaldf_, on='date', how='left')\n",
    "    finaldf.to_csv('./data/{0}/all_normalized.csv'.format(symbol), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['close_delta_1' 'close_delta_2' 'close_delta_3'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0bedc3500d46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/{0}/normalized.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol_tem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'high'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'volume'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close_delta_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close_delta_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close_delta_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msymbol_tem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# if not bool(re.match('.*delta.*', col))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m         )\n\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3946\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5340\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['close_delta_1' 'close_delta_2' 'close_delta_3'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# symbol = 'AAPL'\n",
    "for symbol in symbols:\n",
    "    target_dfs = pd.read_csv('./data/{0}/normalized.csv'.format(symbol),  index_col=[0], parse_dates=[0])\n",
    "    dfs = []\n",
    "    for symbol_tem in symbols:\n",
    "        if symbol_tem == symbol :\n",
    "            pass\n",
    "        df = pd.read_csv('./data/{0}/normalized.csv'.format(symbol_tem), index_col=[0], parse_dates=[0]) \n",
    "        df = df.set_index(df['date'])\n",
    "        df = df.drop(columns = ['date', 'open', 'high', 'low', 'volume', 'close', 'close_delta_1', 'close_delta_2', 'close_delta_3'])\n",
    "        df.columns = [symbol_tem + '_' + col for col in df.columns]   # if not bool(re.match('.*delta.*', col)) \n",
    "        dfs.append(df)\n",
    "\n",
    "    finaldf_ = pd.concat(dfs, axis=1, join='outer')\n",
    "    finaldf_ = finaldf_.reset_index(['date'])\n",
    "    finaldf = target_dfs.merge(finaldf_, on='date', how='left')\n",
    "    finaldf.to_csv('./data/{0}/all_normalized.csv'.format(symbol), index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.set_index('index')\n",
    "finaldf.reset_index(inplace=True)\n",
    "finaldf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(f, index_col=[0], parse_dates=[0]) for f in [] if f.endswith('csv')]\n",
    "\n",
    "finaldf = pd.concat(dfs, axis=1, join='inner').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install AlgoTraderLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vols = [Volatility(ticker).annual for ticker in symbols]\n",
    "dataset = pd.DataFrame({'Symbol':symbols,'Volatility':vols})\n",
    "\n",
    "#volatility distribution\n",
    "dataset.hist()\n",
    "plt.show()\n",
    "plt.savefig(\"./images/volatility_distribution.png\")\n",
    "\n",
    "#box plot to show range\n",
    "dataset.boxplot()\n",
    "plt.show()\n",
    "\n",
    "#volatility statistics\n",
    "dataset.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
