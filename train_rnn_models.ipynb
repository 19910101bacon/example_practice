{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport data_creater\n",
    "%aimport model\n",
    "%autoreload 1\n",
    "\n",
    "from data_creater import *\n",
    "from model import *\n",
    "import re, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = companies()\n",
    "symbols = stocks['Symbol'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "# del df\n",
    "# del stocks, Sequential\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normal_amplitude',\n",
       " 'normal_volume',\n",
       " 'normal_close',\n",
       " 'normal_close_diff_day1',\n",
       " 'normal_close_diff_day2',\n",
       " 'normal_close_diff_day3',\n",
       " 'normal_returns',\n",
       " 'normal_mfi',\n",
       " 'normal_weekday']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = 'MMM'\n",
    "other_symbols = [symbol_tem for symbol_tem in symbols if symbol_tem != symbol]\n",
    "df = pd.read_csv('./data/{0}/all_normalized.csv'.format(symbol), index_col=[0], parse_dates=[0])\n",
    "symbol_columns = [symbol_tem for symbol_tem in list(df.columns.values) if bool(re.match('normal.*', symbol_tem))]\n",
    "\n",
    "box = []\n",
    "for symbol_tem in other_symbols:\n",
    "    box_tem = []\n",
    "    for col in list(df.columns.values):\n",
    "        if bool(re.match(symbol_tem + '_normal_.*', col)):\n",
    "            box_tem.append(col)\n",
    "    box.append(box_tem)\n",
    "\n",
    "all_combination = []\n",
    "all_combination.append(symbol_columns)\n",
    "for box_tem in box:\n",
    "    all_combination.append(symbol_columns + box_tem)\n",
    "    \n",
    "all_combination[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03352107 -0.17754371 -0.3861563   0.70570341  0.54774041  0.66382023\n",
      "   0.64942526 -0.68993871  3.        ]\n",
      " [-0.26815705 -0.2792827  -0.40817555  0.09049326  0.47626233  0.44672878\n",
      "   0.12399471 -0.64910956  4.        ]\n",
      " [-0.60335345 -0.33233866 -0.42354147  0.12243274 -0.06654407  0.41229764\n",
      "   0.15052712 -0.64951155  5.        ]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "ticker = 'AAPL'\n",
    "window_size = 3\n",
    "seq_obj = MultiSequence(ticker,window_size,1,'g000',all_combination[0])\n",
    "\n",
    "\n",
    "# sys.exit()\n",
    "X_train,y_train,X_test,y_test = split_data(seq_obj)\n",
    "print(seq_obj.X[2])\n",
    "print(seq_obj.y[2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [3,4]\n",
    "dropouts =  [0.25]\n",
    "learn_rates = [0.001]\n",
    "epochs = [5,10,30]\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Best Model Selection for AAPL ***\n",
      "============================================================\n",
      "\n",
      "Window size: 3\n",
      "------------------------------------------------------------\n",
      "1    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 5 Training loss: 4.2359 Training acc: 0.6632 Testing loss: 4.7219 Testing acc: 0.3469 Score : 0.4556\n",
      "2    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 10 Training loss: 0.6138 Training acc: 0.7254 Testing loss: 0.6264 Testing acc: 0.6939 Score : 0.7093\n",
      "3    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 30 Training loss: 0.6637 Training acc: 0.7513 Testing loss: 0.9840 Testing acc: 0.6939 Score : 0.7214\n",
      "\n",
      "Window size: 4\n",
      "------------------------------------------------------------\n",
      "4    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 5 Training loss: 0.6055 Training acc: 0.6771 Testing loss: 0.9504 Testing acc: 0.6939 Score : 0.6854\n",
      "5    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 10 Training loss: 0.6894 Training acc: 0.7083 Testing loss: 2.1238 Testing acc: 0.6939 Score : 0.7010\n"
     ]
    }
   ],
   "source": [
    "result = model_selector('AAPL', window_sizes, learn_rates, dropouts, epochs, batch_size,target_length=1,target_theme='g001',verbose=1,column=all_combination[1])\n",
    "\n",
    "print(\"\\nResults : \")\n",
    "print(\"-\"*60)\n",
    "print(result[0])\n",
    "\n",
    "print(result[1])\n",
    "ModelLoader.save(result[1]['ticker'],result[0],result[1],force_overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Best Model Selection for MMM ***\n",
      "============================================================\n",
      "\n",
      "Window size: 1\n",
      "------------------------------------------------------------\n",
      "1    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 500 Training error: 0.0041 Testing error: 0.0065\n",
      "2    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 700 Training error: 0.0040 Testing error: 0.0066\n",
      "3    > Learn rate: 0.0010 Dropout: 0.40 Epoch: 500 Training error: 0.0042 Testing error: 0.0067\n",
      "4    > Learn rate: 0.0010 Dropout: 0.40 Epoch: 700 Training error: 0.0040 Testing error: 0.0066\n",
      "\n",
      "Window size: 2\n",
      "------------------------------------------------------------\n",
      "5    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 500 Training error: 0.0039 Testing error: 0.0067\n",
      "6    > Learn rate: 0.0010 Dropout: 0.25 Epoch: 700 Training error: 0.0038 Testing error: 0.0074\n",
      "7    > Learn rate: 0.0010 Dropout: 0.40 Epoch: 500 Training error: 0.0041 Testing error: 0.0071\n",
      "8    > Learn rate: 0.0010 Dropout: 0.40 Epoch: 700 Training error: 0.0037 Testing error: 0.0075\n",
      "\n",
      "Model selection summary for MMM with window size of 1:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 500 Training error: 0.0041 Testing error: 0.0065\n",
      "\n",
      "Results : \n",
      "------------------------------------------------------------\n",
      "<keras.engine.sequential.Sequential object at 0x1a9c8060d0>\n",
      "{'ticker': 'MMM', 'test_error': 0.0065, 'learn_rate': 0.001, 'dropout': 0.25, 'epoch': 500, 'train_error': 0.0041, 'window_size': 1, 'target_length': 1, 'colname': ['normal_open_', 'normal_high', 'normal_low', 'normal_volume', 'normal_close', 'normal_close_delta_1', 'normal_close_delta_2', 'normal_close_delta_3', 'normal_returns', 'normal_mfi']}\n",
      "Accuracy is lower than the past\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy is lower than the past'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_selector('MMM', window_sizes, learn_rates, dropouts, epochs, batch_size,target_length=1,all_day=False,verbose=1,column=all_combination[0])\n",
    "\n",
    "print(\"\\nResults : \")\n",
    "print(\"-\"*60)\n",
    "print(result[0])\n",
    "\n",
    "print(result[1])\n",
    "ModelLoader.save(result[1]['ticker'],result[0],result[1],force_overwrite=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [2, 5, 6, 7]\n",
    "dropouts =  [0.25, 0.4]\n",
    "learn_rates = [0.001]\n",
    "epochs = [500,1000,1500]\n",
    "batch_size = 30\n",
    "\n",
    "for i in range(len(all_combination)-1):\n",
    "    print(all_combination[i])\n",
    "    print(\"{0} {1} {2}\".format(\"-\"*30, i + 1, \"-\"*30))\n",
    "    result = model_selector(symbols[2], window_sizes, learn_rates, dropouts, epochs, batch_size,target_length=1,all_day=False,verbose=1,column=all_combination[i])\n",
    "\n",
    "    print(\"\\nResults : \")\n",
    "    print(\"-\"*60)\n",
    "    print(result[0])\n",
    "\n",
    "    print(result[1])\n",
    "    ModelLoader.save(result[1]['ticker'],result[0],result[1],force_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_open_</th>\n",
       "      <th>normal_high</th>\n",
       "      <th>normal_low</th>\n",
       "      <th>normal_volume</th>\n",
       "      <th>normal_close</th>\n",
       "      <th>normal_returns</th>\n",
       "      <th>normal_mfi</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.485243</td>\n",
       "      <td>-0.500641</td>\n",
       "      <td>-0.524723</td>\n",
       "      <td>-0.202762</td>\n",
       "      <td>-0.476723</td>\n",
       "      <td>0.368477</td>\n",
       "      <td>-0.727863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.531683</td>\n",
       "      <td>-0.503716</td>\n",
       "      <td>-0.514295</td>\n",
       "      <td>-0.288351</td>\n",
       "      <td>-0.482854</td>\n",
       "      <td>0.187972</td>\n",
       "      <td>-0.714509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.442885</td>\n",
       "      <td>-0.392330</td>\n",
       "      <td>-0.446182</td>\n",
       "      <td>-0.177544</td>\n",
       "      <td>-0.374746</td>\n",
       "      <td>0.649425</td>\n",
       "      <td>-0.689939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.342009</td>\n",
       "      <td>-0.366533</td>\n",
       "      <td>-0.399596</td>\n",
       "      <td>-0.279283</td>\n",
       "      <td>-0.397174</td>\n",
       "      <td>0.123995</td>\n",
       "      <td>-0.649110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.382325</td>\n",
       "      <td>-0.408730</td>\n",
       "      <td>-0.410865</td>\n",
       "      <td>-0.332339</td>\n",
       "      <td>-0.412826</td>\n",
       "      <td>0.150527</td>\n",
       "      <td>-0.649512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.918687</td>\n",
       "      <td>0.909456</td>\n",
       "      <td>0.906660</td>\n",
       "      <td>-0.819771</td>\n",
       "      <td>0.906154</td>\n",
       "      <td>0.218105</td>\n",
       "      <td>0.630991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.952199</td>\n",
       "      <td>0.958315</td>\n",
       "      <td>0.952741</td>\n",
       "      <td>-0.706738</td>\n",
       "      <td>0.954633</td>\n",
       "      <td>0.345839</td>\n",
       "      <td>0.634588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.951348</td>\n",
       "      <td>0.959853</td>\n",
       "      <td>0.931551</td>\n",
       "      <td>-0.854600</td>\n",
       "      <td>0.966261</td>\n",
       "      <td>0.244761</td>\n",
       "      <td>0.464988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.944714</td>\n",
       "      <td>0.994533</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>-0.784475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.304359</td>\n",
       "      <td>0.469215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.751984</td>\n",
       "      <td>0.996069</td>\n",
       "      <td>0.202571</td>\n",
       "      <td>0.481063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     normal_open_  normal_high  normal_low  normal_volume  normal_close  \\\n",
       "0       -0.485243    -0.500641   -0.524723      -0.202762     -0.476723   \n",
       "1       -0.531683    -0.503716   -0.514295      -0.288351     -0.482854   \n",
       "2       -0.442885    -0.392330   -0.446182      -0.177544     -0.374746   \n",
       "3       -0.342009    -0.366533   -0.399596      -0.279283     -0.397174   \n",
       "4       -0.382325    -0.408730   -0.410865      -0.332339     -0.412826   \n",
       "..            ...          ...         ...            ...           ...   \n",
       "238      0.918687     0.909456    0.906660      -0.819771      0.906154   \n",
       "239      0.952199     0.958315    0.952741      -0.706738      0.954633   \n",
       "240      0.951348     0.959853    0.931551      -0.854600      0.966261   \n",
       "241      0.944714     0.994533    0.955600      -0.784475      1.000000   \n",
       "242      1.000000     1.000000    1.000000      -0.751984      0.996069   \n",
       "\n",
       "     normal_returns  normal_mfi  close  \n",
       "0          0.368477   -0.727863      1  \n",
       "1          0.187972   -0.714509      0  \n",
       "2          0.649425   -0.689939      1  \n",
       "3          0.123995   -0.649110      0  \n",
       "4          0.150527   -0.649512      0  \n",
       "..              ...         ...    ...  \n",
       "238        0.218105    0.630991      1  \n",
       "239        0.345839    0.634588      1  \n",
       "240        0.244761    0.464988      1  \n",
       "241        0.304359    0.469215      1  \n",
       "242        0.202571    0.481063      0  \n",
       "\n",
       "[243 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = 'AAPL'\n",
    "window_size = 1\n",
    "seq_obj = MultiSequence(ticker,window_size,1,'g000',all_combination[0])\n",
    "X = seq_obj.data\n",
    "Y = pd.Series(seq_obj.ans)\n",
    "X['close'] = Y\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bacon_huang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.7705 - accuracy: 0.4298\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.7471 - accuracy: 0.4256\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.7292 - accuracy: 0.4050\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.7186 - accuracy: 0.4174\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 94us/step - loss: 0.7119 - accuracy: 0.4545\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.7064 - accuracy: 0.4463\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 80us/step - loss: 0.7022 - accuracy: 0.4752\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 74us/step - loss: 0.6988 - accuracy: 0.4835\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6958 - accuracy: 0.4959\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.6936 - accuracy: 0.5248\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 82us/step - loss: 0.6922 - accuracy: 0.5372\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 74us/step - loss: 0.6908 - accuracy: 0.5331\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 74us/step - loss: 0.6895 - accuracy: 0.5372\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.6886 - accuracy: 0.5537\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 74us/step - loss: 0.6878 - accuracy: 0.5496\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 75us/step - loss: 0.6871 - accuracy: 0.5537\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 82us/step - loss: 0.6865 - accuracy: 0.5661\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6861 - accuracy: 0.5579\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 73us/step - loss: 0.6852 - accuracy: 0.5620\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.6848 - accuracy: 0.5579\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 82us/step - loss: 0.6840 - accuracy: 0.5661\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.6837 - accuracy: 0.5579\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 86us/step - loss: 0.6829 - accuracy: 0.5579\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 87us/step - loss: 0.6826 - accuracy: 0.5579\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6820 - accuracy: 0.5620\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 81us/step - loss: 0.6818 - accuracy: 0.5620\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 87us/step - loss: 0.6816 - accuracy: 0.5661\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 83us/step - loss: 0.6810 - accuracy: 0.5620\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 80us/step - loss: 0.6809 - accuracy: 0.5702\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6804 - accuracy: 0.5661\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.6806 - accuracy: 0.5702\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6801 - accuracy: 0.5661\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 73us/step - loss: 0.6799 - accuracy: 0.5702\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 73us/step - loss: 0.6795 - accuracy: 0.5744\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 72us/step - loss: 0.6793 - accuracy: 0.5744\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 75us/step - loss: 0.6791 - accuracy: 0.5785\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 69us/step - loss: 0.6789 - accuracy: 0.5826\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 70us/step - loss: 0.6789 - accuracy: 0.5868\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 71us/step - loss: 0.6784 - accuracy: 0.5785\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 73us/step - loss: 0.6788 - accuracy: 0.5785\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 82us/step - loss: 0.6781 - accuracy: 0.5785\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 74us/step - loss: 0.6778 - accuracy: 0.5785\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 77us/step - loss: 0.6778 - accuracy: 0.5785\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 75us/step - loss: 0.6773 - accuracy: 0.5785\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.6777 - accuracy: 0.5785\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 71us/step - loss: 0.6769 - accuracy: 0.5785\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 72us/step - loss: 0.6767 - accuracy: 0.5744\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 77us/step - loss: 0.6766 - accuracy: 0.5744\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 74us/step - loss: 0.6761 - accuracy: 0.5744\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 74us/step - loss: 0.6760 - accuracy: 0.5744\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 81us/step - loss: 0.6757 - accuracy: 0.5702\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 77us/step - loss: 0.6754 - accuracy: 0.5702\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 81us/step - loss: 0.6751 - accuracy: 0.5702\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 75us/step - loss: 0.6750 - accuracy: 0.5744\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6746 - accuracy: 0.5826\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 81us/step - loss: 0.6740 - accuracy: 0.5826\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 71us/step - loss: 0.6740 - accuracy: 0.5909\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 72us/step - loss: 0.6740 - accuracy: 0.5826\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 74us/step - loss: 0.6733 - accuracy: 0.5868\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 73us/step - loss: 0.6729 - accuracy: 0.5909\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 86us/step - loss: 0.6729 - accuracy: 0.5868\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6722 - accuracy: 0.5909\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 81us/step - loss: 0.6721 - accuracy: 0.5868\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 79us/step - loss: 0.6716 - accuracy: 0.5992\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 73us/step - loss: 0.6713 - accuracy: 0.5992\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 75us/step - loss: 0.6711 - accuracy: 0.5992\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 73us/step - loss: 0.6708 - accuracy: 0.5992\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 80us/step - loss: 0.6708 - accuracy: 0.5992\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6702 - accuracy: 0.5950\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 80us/step - loss: 0.6696 - accuracy: 0.5992\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 75us/step - loss: 0.6693 - accuracy: 0.6074\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 82us/step - loss: 0.6690 - accuracy: 0.6116\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 75us/step - loss: 0.6684 - accuracy: 0.6116\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 81us/step - loss: 0.6680 - accuracy: 0.6116\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6677 - accuracy: 0.6116\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 86us/step - loss: 0.6666 - accuracy: 0.6157\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6663 - accuracy: 0.6157\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 82us/step - loss: 0.6663 - accuracy: 0.6198\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 77us/step - loss: 0.6654 - accuracy: 0.6157\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 79us/step - loss: 0.6650 - accuracy: 0.6157\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 66us/step - loss: 0.6657 - accuracy: 0.6281\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.6639 - accuracy: 0.6322\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 76us/step - loss: 0.6638 - accuracy: 0.6281\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 80us/step - loss: 0.6636 - accuracy: 0.6240\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 84us/step - loss: 0.6629 - accuracy: 0.6281\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 77us/step - loss: 0.6624 - accuracy: 0.6281\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 80us/step - loss: 0.6623 - accuracy: 0.6240\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 77us/step - loss: 0.6616 - accuracy: 0.6281\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 78us/step - loss: 0.6613 - accuracy: 0.6322\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 84us/step - loss: 0.6614 - accuracy: 0.6322\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 77us/step - loss: 0.6605 - accuracy: 0.6322\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 92us/step - loss: 0.6602 - accuracy: 0.6281\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 94us/step - loss: 0.6606 - accuracy: 0.6240\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 93us/step - loss: 0.6600 - accuracy: 0.6198\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 98us/step - loss: 0.6598 - accuracy: 0.6240\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.6594 - accuracy: 0.6198\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 94us/step - loss: 0.6593 - accuracy: 0.6240\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 93us/step - loss: 0.6588 - accuracy: 0.6281\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 86us/step - loss: 0.6587 - accuracy: 0.6281\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 95us/step - loss: 0.6584 - accuracy: 0.6240\n",
      "242/242 [==============================] - 0s 98us/step\n",
      "\n",
      "Loss: 0.66, Accuracy: 62.81%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type numpy.ndarray doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-510e182e3615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 5. 数据预测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-510e182e3615>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 5. 数据预测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: type numpy.ndarray doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(seq_obj.X)\n",
    "Y = seq_obj.y\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 2. 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 3. 训练模型\n",
    "history = model.fit(X, Y, nb_epoch=100, batch_size=10)\n",
    "# 4. 评估模型\n",
    "loss, accuracy = model.evaluate(X, Y)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "# 5. 数据预测\n",
    "probabilities = model.predict(X)\n",
    "predictions = [float(round(x)) for x in probabilities]\n",
    "accuracy = numpy.mean(predictions == Y)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model selection summary for AXP with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0035 Testing error: 0.0053\n",
      " ==> Saved trained model for AXP\n",
      "\n",
      "Model selection summary for AAPL with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0031 Testing error: 0.0109\n",
      " ==> Saved trained model for AAPL\n",
      "\n",
      "Model selection summary for BA with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0059 Testing error: 0.0031\n",
      " ==> Saved trained model for BA\n",
      "\n",
      "Model selection summary for CAT with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0030 Testing error: 0.0055\n",
      " ==> Saved trained model for CAT\n",
      "\n",
      "Model selection summary for CVX with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.40 Epoch: 100 Training error: 0.0070 Testing error: 0.0106\n",
      " ==> Saved trained model for CVX\n",
      "\n",
      "Model selection summary for CSCO with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.25 Epoch: 100 Training error: 0.0037 Testing error: 0.0079\n",
      " ==> Saved trained model for CSCO\n",
      "\n",
      "Model selection summary for KO with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.25 Epoch: 100 Training error: 0.0037 Testing error: 0.0058\n",
      " ==> Saved trained model for KO\n",
      "\n",
      "Model selection summary for DWDP with window size of 5:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0051 Testing error: 0.0058\n",
      " ==> Saved trained model for DWDP\n",
      "\n",
      "Model selection summary for XOM with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 100 Training error: 0.0103 Testing error: 0.0130\n",
      " ==> Saved trained model for XOM\n",
      "\n",
      "Model selection summary for WBA with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.40 Epoch: 100 Training error: 0.0058 Testing error: 0.0100\n",
      " ==> Saved trained model for WBA\n",
      "\n",
      "Model selection summary for GS with window size of 5:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0093 Testing error: 0.0071\n",
      " ==> Saved trained model for GS\n",
      "\n",
      "Model selection summary for HD with window size of 5:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0018 Testing error: 0.0040\n",
      " ==> Saved trained model for HD\n",
      "\n",
      "Model selection summary for IBM with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.25 Epoch: 200 Training error: 0.0058 Testing error: 0.0097\n",
      " ==> Saved trained model for IBM\n",
      "\n",
      "Model selection summary for INTC with window size of 5:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.25 Epoch: 200 Training error: 0.0033 Testing error: 0.0080\n",
      " ==> Saved trained model for INTC\n",
      "\n",
      "Model selection summary for JNJ with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.40 Epoch: 100 Training error: 0.0052 Testing error: 0.0045\n",
      " ==> Saved trained model for JNJ\n",
      "\n",
      "Model selection summary for JPM with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.25 Epoch: 100 Training error: 0.0026 Testing error: 0.0042\n",
      " ==> Saved trained model for JPM\n",
      "\n",
      "Model selection summary for MCD with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0023 Testing error: 0.0041\n",
      " ==> Saved trained model for MCD\n",
      "\n",
      "Model selection summary for MRK with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0036 Testing error: 0.0449\n",
      " ==> Saved trained model for MRK\n",
      "\n",
      "Model selection summary for MSFT with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 200 Training error: 0.0025 Testing error: 0.0062\n",
      " ==> Saved trained model for MSFT\n",
      "\n",
      "Model selection summary for NKE with window size of 5:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0041 Testing error: 0.0125\n",
      " ==> Saved trained model for NKE\n",
      "\n",
      "Model selection summary for PFE with window size of 5:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 200 Training error: 0.0018 Testing error: 0.0497\n",
      " ==> Saved trained model for PFE\n",
      "\n",
      "Model selection summary for PG with window size of 5:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0046 Testing error: 0.0100\n",
      " ==> Saved trained model for PG\n",
      "\n",
      "Model selection summary for TRV with window size of 5:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0041 Testing error: 0.0047\n",
      " ==> Saved trained model for TRV\n",
      "\n",
      "Model selection summary for UNH with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.25 Epoch: 200 Training error: 0.0028 Testing error: 0.0035\n",
      " ==> Saved trained model for UNH\n",
      "\n",
      "Model selection summary for UTX with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0038 Testing error: 0.0102\n",
      " ==> Saved trained model for UTX\n",
      "\n",
      "Model selection summary for VZ with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.25 Epoch: 100 Training error: 0.0033 Testing error: 0.0100\n",
      " ==> Saved trained model for VZ\n",
      "\n",
      "Model selection summary for V with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0024 Testing error: 0.0062\n",
      " ==> Saved trained model for V\n",
      "\n",
      "Model selection summary for WMT with window size of 7:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0028 Testing error: 0.0033\n",
      " ==> Saved trained model for WMT\n",
      "\n",
      "Model selection summary for DIS with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0089 Testing error: 0.0182\n",
      " ==> Saved trained model for DIS\n",
      "\n",
      "Model selection summary for GOOG with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0100 Dropout: 0.40 Epoch: 100 Training error: 0.0028 Testing error: 0.0099\n",
      " ==> Saved trained model for GOOG\n",
      "\n",
      "Model selection summary for FB with window size of 10:\n",
      "------------------------------------------------------------\n",
      " ==> Learn rate: 0.0010 Dropout: 0.25 Epoch: 200 Training error: 0.0022 Testing error: 0.0106\n",
      " ==> Saved trained model for FB\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "for ticker in symbols[1:]:\n",
    "    #release memory\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    result = model_selector(ticker, window_sizes, learn_rates, dropouts, epochs, batch_size,verbose=2)\n",
    "    \n",
    "    #save trained model\n",
    "    ModelLoader.save(result[1]['ticker'],result[0],result[1])\n",
    "    print(\" ==> Saved trained model for {}\".format(result[1]['ticker']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
